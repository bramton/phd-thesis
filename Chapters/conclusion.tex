\chapter{Conclusions and Future work}\label{chap:conclusion}
This thesis has focused on creating a digital representation of the rail environment using point cloud data. Such a digital representation can be used for a range of applications such as asset management, change detection, robotised construction, and predictive maintenance. This thesis has taken a top-down approach, first large objects are detected within the point cloud data. Thereafter, it has focused on dissecting these large objects into smaller meaningful pieces by semantic segmentation of point cloud data. This increases the level of detail of the digital representation. These two steps conclude the translation from the physical world to cyber space. To complete the cycle, going from cyber space to the physical world again, this thesis has also focused on how information from cyber space can be visualised in an intuitive, immersive way using a head mounted display.

For the object detection and segmentation tasks, the major limitation was the virtually non-existence of labelled data. Therefore, two custom datasets have been collected and annotated during this research. These datasets has been made publicly available. Despite the laborious endeavour of annotating the data, these datasets are not large enough to provide answers with high measures of significance. Nonetheless, several interesting results and insights have originated from these datasets. Each of the individual sub-research questions will be answered explicitly in the following paragraphs.

\begin{quote}
    \textbf{RQ1} To what extent are machine learning models aimed at autonomous driving suitable for detecting objects within the railway environment at large scale?
\end{quote}
Based on the results of Chapter~\ref{chap:objdet}, it can be concluded that, out-of-the box, these models can be used to detect railway assets at large scale, but they do not provide the required locational accuracy required by the engineering applications which depend on information from the digital representation. Another limitation of the current research is that the models have only been used to detect large objects. This limitation was imposed by the fact that the laser scanner used to collect the data had a limited spatial resolution.

Because railway assets exhibit large intra-class variation and because of the fact that labelling data is a time-consuming and tedious task, the possibility of transfer learning has been explored. Preliminary results have shown a positive outcome, indicating that existing models can be fine tuned with just a small amount of labelled data. This would greatly reduce the amount of effort required to apply existing models to new and different railway scenes.

\begin{quote}
    \textbf{RQ2} To what extent can semantic segmentation be used to gain a higher level of detail when capturing the railway scene in cyber space?
\end{quote}
To answer this question, Chapter~\ref{chap:semseg} presents the work which was focused on semantically segmenting catenary masts, that is, each point within the point cloud is assigned a semantically meaningful label. A dataset with a high spatial resolution point cloud was collected for this purpose. Three state-of-the-art models have been evaluated for this case. Challenges identified during this evaluation, were the large class imbalance present and the large compositional variation of catenary arches. To counter the substantial class imbalance of the dataset, the models were also trained using inverse class weights. Surprisingly, this had a negligible effect on the results and in some cases it was even destructive. To cope with the large compositional variation of catenary arches and the limited size of the dataset, a leave-one-out-cross-validation method was used. In the end, the best performing model was a modified \pnpp{} model, which achieved an overall mIoU of 71\% across 14 distinct classes.

Thus, semantic segmentation can provide a higher level of detail during the digitisation process of the railway environment. Only caveat here is that high spatial resolution point cloud must be available in the first place.

\begin{quote}
    \textbf{RQ3} How can immersive visualisation using a head-mounted display add value to visualising point cloud data and information from cyber space?
\end{quote}
To answer this question, a proof-of-concept has been created and is presented in Chapter~\ref{chap:immvis}. This proof-of-concept is can load point cloud files and enables user interaction with the point cloud using a head-mounted display. Two modes of interaction were supported, hand gestures and voice commands. Based on a user evaluation of the proof-of-concept, it can be concluded that this form of visualisation does indeed provide an intuitive method of dealing with point cloud data. Added value is creating by letting users use hand gestures to rotate, scale and translate the point cloud to get the best vantage point. It is certainly worthwhile to further develop the proof-of-concept into a more mature product. Points of improvement are the automatic level of detail depending on the scale level, extending the number of hand gestures supported, and tying more data sources into the visualisation.

Based on the insights from the intermediate research questions, the main research question can now be addressed. The main research question has been restated below for convenience.
\begin{quote}
    \textbf{MRQ} What is needed to guarantee that translations at large scale from the physical rail environment into cyber space using point cloud data is accurate enough for tasks such as, planning activities, visualisations, and predictive maintenance ?
\end{quote}
A hierarchical approach, working top-down from large assets to individual component level is advisable. In this scenario, first objects are detected and later scrutinised further using, for instance, a segmentation model. Care has to be taken with regards to locational accuracy. Current models from the domain of autonomous driving do not yet provide the required locational accuracy. The chosen direction which focuses on object detection followed by semantic segmentation is promising, but still requires significant research effort to achieve the required maturity such that it can be used in operational environments. Several of these research efforts are described at the end of this chapter after the contributions section.

Furthermore to guarantee accurate translations of small scale objects to cyberspace, high spatial resolution point cloud data is required. This comes with downside, as current models cannot directly cope with the sheer volume of 3D point cloud data. Therefore a considerable effort was required to cull the number of points such that the models can actually work with them. Furthermore, both the object detection and semantic segmentation models used in this research are trained in a fully supervised manner. Though this is a straight-forward approach, it has as downside that it requires large amounts of labelled data. Therefore it is recommended to look at alternative approaches to training these models in the future.

\section{Contributions}
The main contributions of this thesis are listed below. 

\paragraph{Contribution 1: Evaluation of autonomous driving models adaptability to railway asset detection.}
The persuasion of the ultimate goal to have autonomous driving vehicles has led to technologies focusing on detecting other road users such as other vehicles, cyclists and pedestrians. To do so, state-of-the art autonomous vehicles are often equipped with laser scanning technology which capture the environment as a point cloud. Obstacle and impact avoidance decisions are based on this point cloud data using innovative deep-learning models. These decisions need to be done in near real-time, thus requiring very low inference times. This thesis has evaluated the adaptability of these models to detect railway objects. This evaluation included an in-depth analysis of the locational accuracy; such an in-depth analysis is often omitted for practical reasons. Based on the locational accuracy analysis it is concluded that the locational accuracy provided by these models is not yet sufficient for engineering applications which depend on this data. \textit{Chapter~\ref{chap:objdet}.}

\paragraph{Contribution 2: Datasets.}
At the initiation of this work, there where no public point cloud datasets available for the rail domain. However, during the course of this work, several public datasets have emerged, underlining the importance of this new research area. This work has also contributed two datasets to this growing corpus of public datasets. The first contributed dataset is dedicated to the semantic segmentation task and consists of high resolution scans of catenary arches with 14 distinct classes labelled. The second contributed dataset has a hybrid nature, it can be used for both object detection and semantic segmentation tasks. This hybrid nature is enabled by the fact that each point has a label and semantic groups have a unique identifier. \textit{Chapters~\ref{chap:objdet} and~\ref{chap:semseg}.}

\paragraph{Contribution 3: Immersive visualisation of railway point cloud scenes.}
Viewing 3D data on a 2D dimensional screen provides a superficial experience and lacks intuition. To gain a rich intuitive experience, 3D data can be best viewed in a 3D environment. This thesis has demonstrated a working prototype to immersively view railway point cloud scenes using a head-mounted display. Users are able to interact with the scene using hand gestures and voice commands. \textit{Chapter~\ref{chap:immvis}.}

\paragraph{Contribution 4: Gap identification.}
A strong case is made for stepping away from fully supervised machine learning approaches. The railway environment is such a complex and diverse scene, it would be impossible to capture this knowledge in a single machine learning model which is trained in a fully-supervised way. The gap to be filled lies within the area of self-supervised learning (SSL). Self-supervised learning is an approach to utilise the enormous amounts of unlabelled data which are available. SSL makes it possible to capture information into the model without supervision. With a few labelled examples the model can then be easily fine tuned to new scenarios.

\section{Future work}
In general, one of the bottlenecks encountered during this research was the virtual non-existence of public datasets for the object detection and the semantic segmentation tasks. At the time the research was initiated, no public datasets for these tasks were available. Creating these datasets ourselves proved to be a time-consuming task, as labelling 3D data is cumbersome. This also highlights one of the shortcomings of current approaches which rely solely on fully supervised machine learning. Another challenge of the rail domain is the representational diversity of objects within the railway environment, not only across countries but also within the same country. To label all variations would be a herculean task. Labels are scarce and expensive to obtain, but unlabelled data is cheap to obtain and ubiquitous. Therefore, a paradigm shift is required which removes, or at least significantly reduces, the dependency on labelled data. Self-supervised learning is such a paradigm which learns latent representations from unlabelled data and is a highly recommended future research direction. With a minimal amount of labels, possibly provided by a human in the loop, these self-supervised learning models should be able to quickly achieve accurate results. 

When considering the semantic segmentation task of catenary arches, which is hampered by the large number of configurations possible, synthetic data can provide some relief. This synthetic data can be created by taking existing labelled data and recombining individual components of this data based on a set of heuristic rules. Some promising results in this direction are already available~\cite{Neri22, uggla2021towards, dekker2023semi}. It is advisable to draft these heuristic rules together with a domain expert.

Annotating 3D point clouds is a weary task if done on a regular computer screen. The related work section of the immersive visualisation chapter (Chapter~\ref{chap:immvis}) has shown some promising results to do this labelling in an immersive setting instead of on a traditional 2D screen. Most approaches make use of some kind of `wand' which is used to paint parts of the point cloud a specific colour. The colour of course corresponds to a certain asset class.  The recommendation is to further explore the immersive visualisation direction and expand the functionality of the current visualisation prototype with labelling abilities.

The locational accuracy of the current object detection models needs improvement. First a careful analysis should be done to identify which elements have the largest contribution to the error. For precise engineering applications, such as automated maintenance operations, the current locational accuracy is not enough. Future work should focus on improving this locational accuracy. This could be done using an additional post-processing step or by penalizing the model for inaccurate results as part of the loss function. In addition, alternative models can be explored which do not depend on grid based methods. Furthermore, special care has to be taken of the orientation of objects. Currently, objects are detected, but it is not known how they are oriented in space. Care should be taken that during the labelling process this property is encoded as well.

The current research has focused on a single data modality, i.e., point cloud data obtained from a laser scanning process. For future work it is recommended to fuse this point cloud with image data as well. Image data adds valuable colour information, which can be used to increase the detection accuracies.

\clearpage
\printbibliography[heading=subbibnumbered]